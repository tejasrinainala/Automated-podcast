# Automated Audio Analysis for Podcast Transcription and Segmentation

## Problem
Podcasts and long-form audio content are difficult to search, review, and analyze because they exist only as raw audio. Listening to entire audio files is time-consuming and inefficient.

This project builds an automated audio analysis system that converts audio into structured text using speech-to-text transcription and timestamp-based segmentation. The system makes audio content easier to understand, review, and reuse.

---

## Architecture
The system follows a simple client–server architecture where audio is uploaded through a web interface and processed using a backend service.

### System Flow
1. User uploads an audio file through the web interface  
2. Backend receives and stores the audio  
3. Whisper ASR converts speech into text  
4. Transcription is segmented using timestamps  
5. Results are displayed and available for download  

**Figure 1: System Architecture for Audio Analysis Pipeline**  

---

## Tech Stack
- **ASR (GenAI):** OpenAI Whisper  
- **LLM:** Whisper (GenAI-based speech-to-text)  
- **Vector Database:** Not used (future enhancement)  
- **Backend:** Flask (Python)  
- **UI:** HTML, CSS, JavaScript  

---

## Pipeline
**Audio → Transcription → Segmentation → Output**

The system currently performs transcription and timestamp-based segmentation.  
Additional steps such as audio cleaning and GenAI-powered summarization are planned as future enhancements.

**Figure 2: Audio Processing Pipeline**

---

## Topic Segmentation Logic
Segmentation is implemented using timestamp information generated by the Whisper model. Each segment includes:
- Start time  
- End time  
- Transcribed speech  

This approach divides long audio into smaller, readable chunks that can be easily reviewed by humans.

---

## GenAI Usage
GenAI is used in the form of the Whisper model for automatic speech recognition. Whisper generates textual output from audio input.

Advanced GenAI features such as topic summarization, insight generation, and semantic analysis are not implemented in the current version and are considered future scope.

---

## Prompt Strategy
Prompt-based interaction with large language models is not used in the current implementation. The system relies on Whisper’s internal inference mechanism.

Prompt strategies will be introduced if future enhancements such as summarization or topic extraction are added.

---

## Safety Handling
Basic safety handling is implemented to ensure reliable system behavior:
- Only valid audio files are accepted  
- Audio with no detectable speech does not produce hallucinated output  
- Outputs are generated strictly based on transcription results  

These measures reduce the risk of incorrect or misleading outputs.

---

## Cost Optimization
The system is designed to be cost-efficient:
- A smaller Whisper model is used to reduce computational requirements  
- No continuous LLM or paid API calls are used  
- The system can run on limited hardware  

---

## Human-in-the-Loop
Human validation is supported by:
- Viewing transcription and segmented output  
- Downloading outputs for manual verification and correction  

This ensures transparency and trust in the generated results.

**Figure 3: Human Review and Validation Flow**

---

## How to Run
1. Clone the project repository  
2. Install required dependencies  
3. Run the backend server  
4. Upload an audio file through the web interface  
5. View or download transcription and segmentation results  

---

## Demo

### Step 1: Home Page – Audio Upload
The home page allows users to upload an audio file for analysis.

### Step 2: Select Audio File
Select an audio file to upload and process.

### Step 3: Audio Upload and Analysis
Click the **Analyze Audio** button to start transcription and segmentation.

### Step 4: Segmented Output with Timestamps
The audio is segmented into smaller parts with start time, end time, and transcribed text.

### Step 5: View and Download Options
Users can view the transcription and download transcript and segmented timestamp files.

Users can manually review the transcription and segmentation results before using or sharing them.

---

## Future Enhancements
- GenAI-based summarization  
- Topic-wise labeling  
- Semantic search using vector databases  
- Advanced safety handling  

